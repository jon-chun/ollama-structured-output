========== TEXT REPORT SUMMARY ==========

Top & Bottom Models (by F1 Score):
----------------------------------

Model: llama3.1:8b-instruct-q4_K_M_(system1)
  F1 Score: 0.5870
  Accuracy: 62.0000
  Precision: 0.4576
  Recall: 0.8182
  Execution Time (mean): 0.2795
  Execution Time (sd): 0.7230
  Eval Duration (mean): 162510000.0000
  Prompt Eval Count (mean): 248.68
  Eval Count (mean): 17.00


Model: falcon3:7b-instruct-q4_K_M_(system1)
  F1 Score: 0.5682
  Accuracy: 62.0000
  Precision: 0.4630
  Recall: 0.7353
  Execution Time (mean): 0.3150
  Execution Time (sd): 0.5265
  Eval Duration (mean): 221770000.0000
  Prompt Eval Count (mean): 267.51
  Eval Count (mean): 26.00


Model: gemma2:9b-instruct-q4_K_M_(cot_nshot)
  F1 Score: 0.5625
  Accuracy: 58.0000
  Precision: 0.4355
  Recall: 0.7941
  Execution Time (mean): 4.0741
  Execution Time (sd): 0.5169
  Eval Duration (mean): 3457570000.0000
  Prompt Eval Count (mean): 2048.00
  Eval Count (mean): 276.35


Model: athene-v2:72b-q4_K_M_(cot_nshot)
  F1 Score: 0.5517
  Accuracy: 63.8889
  Precision: 0.4706
  Recall: 0.6667
  Execution Time (mean): 58.5299
  Execution Time (sd): 7.5097
  Eval Duration (mean): 54082708333.3333
  Prompt Eval Count (mean): 2048.00
  Eval Count (mean): 362.76


Model: olmo2:7b-1124-instruct-q4_K_M_(system1)
  F1 Score: 0.5479
  Accuracy: 67.0000
  Precision: 0.4000
  Recall: 0.8696
  Execution Time (mean): 0.1993
  Execution Time (sd): 0.3688
  Eval Duration (mean): 124340000.0000
  Prompt Eval Count (mean): 249.70
  Eval Count (mean): 13.00


Model: athene-v2:72b-q4_K_M_(cot)
  F1 Score: 0.5455
  Accuracy: 60.0000
  Precision: 0.4138
  Recall: 0.8000
  Execution Time (mean): 62.1297
  Execution Time (sd): 6.6110
  Eval Duration (mean): 61464570000.0000
  Prompt Eval Count (mean): 330.60
  Eval Count (mean): 425.93


Model: qwen2.5:72b-instruct-q4_K_M_(cot_nshot)
  F1 Score: 0.5432
  Accuracy: 63.0000
  Precision: 0.5000
  Recall: 0.5946
  Execution Time (mean): 57.9709
  Execution Time (sd): 6.4867
  Eval Duration (mean): 53533320000.0000
  Prompt Eval Count (mean): 2048.00
  Eval Count (mean): 359.62


Model: marco-o1:7b-q4_K_M_(cot_nshot)
  F1 Score: 0.5361
  Accuracy: 55.0000
  Precision: 0.3714
  Recall: 0.9630
  Execution Time (mean): 2.8180
  Execution Time (sd): 0.3715
  Eval Duration (mean): 2383310000.0000
  Prompt Eval Count (mean): 2048.00
  Eval Count (mean): 271.72


Model: athene-v2:72b-q4_K_M_(system1)
  F1 Score: 0.5333
  Accuracy: 65.0000
  Precision: 0.4082
  Recall: 0.7692
  Execution Time (mean): 3.4656
  Execution Time (sd): 4.6348
  Eval Duration (mean): 2480600000.0000
  Prompt Eval Count (mean): 251.95
  Eval Count (mean): 18.00


Model: llama3.3:70b-instruct-q4_K_M_(cot_nshot)
  F1 Score: 0.5278
  Accuracy: 66.0000
  Precision: 0.4318
  Recall: 0.6786
  Execution Time (mean): 26.4581
  Execution Time (sd): 3.3191
  Eval Duration (mean): 22981990000.0000
  Prompt Eval Count (mean): 2048.00
  Eval Count (mean): 380.90


Model: nemotron-mini:4b-instruct-q4_K_M_(system1)
  F1 Score: 0.2963
  Accuracy: 62.0000
  Precision: 0.2857
  Recall: 0.3077
  Execution Time (mean): 0.2401
  Execution Time (sd): 0.4050
  Eval Duration (mean): 139400000.0000
  Prompt Eval Count (mean): 261.84
  Eval Count (mean): 19.90


Model: mistral:7b-instruct-q4_K_M_(cot)
  F1 Score: 0.2941
  Accuracy: 52.0000
  Precision: 0.2381
  Recall: 0.3846
  Execution Time (mean): 2.9245
  Execution Time (sd): 1.0996
  Eval Duration (mean): 2887590000.0000
  Prompt Eval Count (mean): 363.84
  Eval Count (mean): 366.01


Model: qwen2.5:7b-instruct-q4_K_M_(system1)
  F1 Score: 0.2745
  Accuracy: 63.0000
  Precision: 0.3333
  Recall: 0.2333
  Execution Time (mean): 0.2787
  Execution Time (sd): 0.6334
  Eval Duration (mean): 164870000.0000
  Prompt Eval Count (mean): 252.04
  Eval Count (mean): 18.00


Model: tulu3:8b-q4_K_M_(system1)
  F1 Score: 0.2647
  Accuracy: 50.0000
  Precision: 0.2000
  Recall: 0.3913
  Execution Time (mean): 0.2498
  Execution Time (sd): 0.7492
  Eval Duration (mean): 130290000.0000
  Prompt Eval Count (mean): 249.70
  Eval Count (mean): 13.00


Model: marco-o1:7b-q4_K_M_(system1)
  F1 Score: 0.2553
  Accuracy: 65.0000
  Precision: 0.3000
  Recall: 0.2222
  Execution Time (mean): 0.2849
  Execution Time (sd): 0.7164
  Eval Duration (mean): 165200000.0000
  Prompt Eval Count (mean): 250.05
  Eval Count (mean): 18.00


Model: qwen2.5:1.5b-instruct-q4_K_M_(cot)
  F1 Score: 0.2500
  Accuracy: 64.0000
  Precision: 0.3529
  Recall: 0.1935
  Execution Time (mean): 1.4244
  Execution Time (sd): 0.4420
  Eval Duration (mean): 1374350000.0000
  Prompt Eval Count (mean): 330.73
  Eval Count (mean): 347.66


Model: qwen2.5:0.5b-instruct-q4_K_M_(system1)
  F1 Score: 0.2000
  Accuracy: 52.0000
  Precision: 0.2069
  Recall: 0.1935
  Execution Time (mean): 0.1385
  Execution Time (sd): 0.1974
  Eval Duration (mean): 67360000.0000
  Prompt Eval Count (mean): 252.61
  Eval Count (mean): 18.41


Model: qwen2.5:14b-instruct-q4_K_M_(system1)
  F1 Score: 0.1702
  Accuracy: 61.0000
  Precision: 0.1538
  Recall: 0.1905
  Execution Time (mean): 0.4627
  Execution Time (sd): 1.0219
  Eval Duration (mean): 283130000.0000
  Prompt Eval Count (mean): 251.46
  Eval Count (mean): 18.00


Model: mistral:7b-instruct-q4_K_M_(cot_nshot)
  F1 Score: 0.0984
  Accuracy: 45.0000
  Precision: 0.0857
  Recall: 0.1154
  Execution Time (mean): 2.4661
  Execution Time (sd): 0.7119
  Eval Duration (mean): 2026680000.0000
  Prompt Eval Count (mean): 2048.00
  Eval Count (mean): 236.91


Model: smallthinker:3b-preview-q4_K_M_(cot_nshot)
  F1 Score: 0.0000
  Accuracy: 0.0000
  Precision: 0.0000
  Recall: 0.0000
  Execution Time (mean): 5.3261
  Execution Time (sd): 0.0000
  Eval Duration (mean): 4838000000.0000
  Prompt Eval Count (mean): 2048.00
  Eval Count (mean): 708.00


Additional Metadata:


  Average F1 Score (across entire dataset): 0.4240

========== END OF TEXT REPORT ==========
