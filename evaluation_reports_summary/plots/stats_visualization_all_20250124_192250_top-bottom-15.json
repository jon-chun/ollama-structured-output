{
  "llama3.1:8b-instruct-q4_K_M_(system1)": {
    "f1_score": 0.5869565217391305,
    "accuracy": 62.0,
    "precision": 0.4576271186440678,
    "recall": 0.8181818181818182,
    "execution_time_mean": 0.2794873762130737,
    "execution_time_sd": 0.723018972162756,
    "eval_duration_mean": 162510000.0,
    "prompt_eval_count_mean": 248.68,
    "eval_count_mean": 17.0
  },
  "falcon3:7b-instruct-q4_K_M_(system1)": {
    "f1_score": 0.5681818181818182,
    "accuracy": 62.0,
    "precision": 0.4629629629629629,
    "recall": 0.7352941176470589,
    "execution_time_mean": 0.3149938488006591,
    "execution_time_sd": 0.526460361328945,
    "eval_duration_mean": 221770000.0,
    "prompt_eval_count_mean": 267.51,
    "eval_count_mean": 26.0
  },
  "gemma2:9b-instruct-q4_K_M_(cot_nshot)": {
    "f1_score": 0.5625,
    "accuracy": 58.0,
    "precision": 0.4354838709677419,
    "recall": 0.7941176470588235,
    "execution_time_mean": 4.074102849960327,
    "execution_time_sd": 0.5169124846616301,
    "eval_duration_mean": 3457570000.0,
    "prompt_eval_count_mean": 2048.0,
    "eval_count_mean": 276.35
  },
  "athene-v2:72b-q4_K_M_(cot_nshot)": {
    "f1_score": 0.5517241379310345,
    "accuracy": 63.888888888888886,
    "precision": 0.4705882352941176,
    "recall": 0.6666666666666666,
    "execution_time_mean": 58.529864854282806,
    "execution_time_sd": 7.509692119399419,
    "eval_duration_mean": 54082708333.333336,
    "prompt_eval_count_mean": 2048.0,
    "eval_count_mean": 362.7638888888889
  },
  "olmo2:7b-1124-instruct-q4_K_M_(system1)": {
    "f1_score": 0.547945205479452,
    "accuracy": 67.0,
    "precision": 0.4,
    "recall": 0.8695652173913043,
    "execution_time_mean": 0.1993295049667358,
    "execution_time_sd": 0.3688461353791612,
    "eval_duration_mean": 124340000.0,
    "prompt_eval_count_mean": 249.7,
    "eval_count_mean": 13.0
  },
  "athene-v2:72b-q4_K_M_(cot)": {
    "f1_score": 0.5454545454545454,
    "accuracy": 60.0,
    "precision": 0.4137931034482758,
    "recall": 0.8,
    "execution_time_mean": 62.12971167564392,
    "execution_time_sd": 6.611031971496379,
    "eval_duration_mean": 61464570000.0,
    "prompt_eval_count_mean": 330.6,
    "eval_count_mean": 425.93
  },
  "qwen2.5:72b-instruct-q4_K_M_(cot_nshot)": {
    "f1_score": 0.5432098765432098,
    "accuracy": 63.0,
    "precision": 0.5,
    "recall": 0.5945945945945946,
    "execution_time_mean": 57.9708509850502,
    "execution_time_sd": 6.486735617728032,
    "eval_duration_mean": 53533320000.0,
    "prompt_eval_count_mean": 2048.0,
    "eval_count_mean": 359.62
  },
  "marco-o1:7b-q4_K_M_(cot_nshot)": {
    "f1_score": 0.5360824742268041,
    "accuracy": 55.0,
    "precision": 0.3714285714285714,
    "recall": 0.9629629629629628,
    "execution_time_mean": 2.81797336101532,
    "execution_time_sd": 0.3715431014579101,
    "eval_duration_mean": 2383310000.0,
    "prompt_eval_count_mean": 2048.0,
    "eval_count_mean": 271.72
  },
  "athene-v2:72b-q4_K_M_(system1)": {
    "f1_score": 0.5333333333333333,
    "accuracy": 65.0,
    "precision": 0.4081632653061224,
    "recall": 0.7692307692307693,
    "execution_time_mean": 3.4656481552124023,
    "execution_time_sd": 4.634826238400708,
    "eval_duration_mean": 2480600000.0,
    "prompt_eval_count_mean": 251.95,
    "eval_count_mean": 18.0
  },
  "llama3.3:70b-instruct-q4_K_M_(cot_nshot)": {
    "f1_score": 0.5277777777777777,
    "accuracy": 66.0,
    "precision": 0.4318181818181818,
    "recall": 0.6785714285714286,
    "execution_time_mean": 26.458070156574248,
    "execution_time_sd": 3.3191497596723814,
    "eval_duration_mean": 22981990000.0,
    "prompt_eval_count_mean": 2048.0,
    "eval_count_mean": 380.9
  },
  "olmo2:7b-1124-instruct-q4_K_M_(cot)": {
    "f1_score": 0.5190839694656488,
    "accuracy": 37.0,
    "precision": 0.3505154639175257,
    "recall": 1.0,
    "execution_time_mean": 2.812553286552429,
    "execution_time_sd": 0.6786860276996655,
    "eval_duration_mean": 2770260000.0,
    "prompt_eval_count_mean": 326.85,
    "eval_count_mean": 329.81
  },
  "exaone3.5:7.8b-instruct-q4_K_M_(cot_nshot)": {
    "f1_score": 0.5185185185185185,
    "accuracy": 48.0,
    "precision": 0.3835616438356164,
    "recall": 0.8,
    "execution_time_mean": 2.912698037624359,
    "execution_time_sd": 0.3186800033037114,
    "eval_duration_mean": 2437790000.0,
    "prompt_eval_count_mean": 2048.0,
    "eval_count_mean": 277.16
  },
  "llama3.2:3b-instruct-q4_K_M_(system1)": {
    "f1_score": 0.5161290322580646,
    "accuracy": 70.0,
    "precision": 0.5,
    "recall": 0.5333333333333333,
    "execution_time_mean": 0.1849521994590759,
    "execution_time_sd": 0.4087995217896963,
    "eval_duration_mean": 100950000.0,
    "prompt_eval_count_mean": 258.39,
    "eval_count_mean": 17.0
  },
  "qwen2.5:3b-instruct-q4_K_M_(system1)": {
    "f1_score": 0.5142857142857142,
    "accuracy": 66.0,
    "precision": 0.4390243902439024,
    "recall": 0.6206896551724138,
    "execution_time_mean": 0.2025569605827331,
    "execution_time_sd": 0.3337180246255601,
    "eval_duration_mean": 114160000.0,
    "prompt_eval_count_mean": 251.92,
    "eval_count_mean": 18.0
  },
  "command-r:35b-08-2024-q4_K_M_(cot)": {
    "f1_score": 0.5128205128205129,
    "accuracy": 43.0,
    "precision": 0.3529411764705882,
    "recall": 0.9375,
    "execution_time_mean": 9.97040977716446,
    "execution_time_sd": 1.8151195768953936,
    "eval_duration_mean": 9849100000.0,
    "prompt_eval_count_mean": 331.94,
    "eval_count_mean": 352.51
  },
  "phi4:14b-q4_K_M_(cot_nshot)": {
    "f1_score": 0.3571428571428571,
    "accuracy": 46.0,
    "precision": 0.234375,
    "recall": 0.75,
    "execution_time_mean": 8.128828809261321,
    "execution_time_sd": 1.847015249709764,
    "eval_duration_mean": 7301570000.0,
    "prompt_eval_count_mean": 2048.0,
    "eval_count_mean": 494.78
  },
  "qwen2.5:0.5b-instruct-q4_K_M_(cot)": {
    "f1_score": 0.35,
    "accuracy": 48.0,
    "precision": 0.28,
    "recall": 0.4666666666666667,
    "execution_time_mean": 0.578096752166748,
    "execution_time_sd": 0.2978822005754267,
    "eval_duration_mean": 529590000.0,
    "prompt_eval_count_mean": 330.7,
    "eval_count_mean": 178.25
  },
  "llama3.2:1b-instruct-q4_K_M_(cot)": {
    "f1_score": 0.3418803418803419,
    "accuracy": 23.0,
    "precision": 0.2061855670103092,
    "recall": 1.0,
    "execution_time_mean": 0.6679856276512146,
    "execution_time_sd": 0.3448872734867183,
    "eval_duration_mean": 631880000.0,
    "prompt_eval_count_mean": 336.98,
    "eval_count_mean": 232.58
  },
  "qwen2.5:3b-instruct-q4_K_M_(cot_nshot)": {
    "f1_score": 0.3243243243243243,
    "accuracy": 50.0,
    "precision": 0.2553191489361702,
    "recall": 0.4444444444444444,
    "execution_time_mean": 1.872595989704132,
    "execution_time_sd": 0.3611670735846721,
    "eval_duration_mean": 1562560000.0,
    "prompt_eval_count_mean": 2048.0,
    "eval_count_mean": 258.62
  },
  "llama3.2:1b-instruct-q4_K_M_(system1)": {
    "f1_score": 0.3037974683544304,
    "accuracy": 45.0,
    "precision": 0.2181818181818181,
    "recall": 0.5,
    "execution_time_mean": 0.1211078262329101,
    "execution_time_sd": 0.2114132830192533,
    "eval_duration_mean": 60800000.0,
    "prompt_eval_count_mean": 257.44,
    "eval_count_mean": 18.44
  },
  "nemotron-mini:4b-instruct-q4_K_M_(system1)": {
    "f1_score": 0.2962962962962963,
    "accuracy": 62.0,
    "precision": 0.2857142857142857,
    "recall": 0.3076923076923077,
    "execution_time_mean": 0.240062153339386,
    "execution_time_sd": 0.4050278118587706,
    "eval_duration_mean": 139400000.0,
    "prompt_eval_count_mean": 261.84,
    "eval_count_mean": 19.9
  },
  "mistral:7b-instruct-q4_K_M_(cot)": {
    "f1_score": 0.2941176470588235,
    "accuracy": 52.0,
    "precision": 0.238095238095238,
    "recall": 0.3846153846153846,
    "execution_time_mean": 2.924485936164856,
    "execution_time_sd": 1.0996494712905334,
    "eval_duration_mean": 2887590000.0,
    "prompt_eval_count_mean": 363.84,
    "eval_count_mean": 366.01
  },
  "qwen2.5:7b-instruct-q4_K_M_(system1)": {
    "f1_score": 0.2745098039215686,
    "accuracy": 63.0,
    "precision": 0.3333333333333333,
    "recall": 0.2333333333333333,
    "execution_time_mean": 0.2786844944953918,
    "execution_time_sd": 0.6333776243755529,
    "eval_duration_mean": 164870000.0,
    "prompt_eval_count_mean": 252.04,
    "eval_count_mean": 18.0
  },
  "tulu3:8b-q4_K_M_(system1)": {
    "f1_score": 0.2647058823529412,
    "accuracy": 50.0,
    "precision": 0.2,
    "recall": 0.391304347826087,
    "execution_time_mean": 0.2497602462768554,
    "execution_time_sd": 0.7492349780810299,
    "eval_duration_mean": 130290000.0,
    "prompt_eval_count_mean": 249.7,
    "eval_count_mean": 13.0
  },
  "marco-o1:7b-q4_K_M_(system1)": {
    "f1_score": 0.2553191489361702,
    "accuracy": 65.0,
    "precision": 0.3,
    "recall": 0.2222222222222222,
    "execution_time_mean": 0.2849130177497864,
    "execution_time_sd": 0.7164429927365797,
    "eval_duration_mean": 165200000.0,
    "prompt_eval_count_mean": 250.05,
    "eval_count_mean": 18.0
  },
  "qwen2.5:1.5b-instruct-q4_K_M_(cot)": {
    "f1_score": 0.25,
    "accuracy": 64.0,
    "precision": 0.3529411764705882,
    "recall": 0.1935483870967742,
    "execution_time_mean": 1.424448652267456,
    "execution_time_sd": 0.4420240356700368,
    "eval_duration_mean": 1374350000.0,
    "prompt_eval_count_mean": 330.73,
    "eval_count_mean": 347.66
  },
  "qwen2.5:0.5b-instruct-q4_K_M_(system1)": {
    "f1_score": 0.1999999999999999,
    "accuracy": 52.0,
    "precision": 0.2068965517241379,
    "recall": 0.1935483870967742,
    "execution_time_mean": 0.1384516048431396,
    "execution_time_sd": 0.1973685089675919,
    "eval_duration_mean": 67360000.0,
    "prompt_eval_count_mean": 252.61,
    "eval_count_mean": 18.41
  },
  "qwen2.5:14b-instruct-q4_K_M_(system1)": {
    "f1_score": 0.1702127659574468,
    "accuracy": 61.0,
    "precision": 0.1538461538461538,
    "recall": 0.1904761904761904,
    "execution_time_mean": 0.4627179050445557,
    "execution_time_sd": 1.021858580354548,
    "eval_duration_mean": 283130000.0,
    "prompt_eval_count_mean": 251.46,
    "eval_count_mean": 18.0
  },
  "mistral:7b-instruct-q4_K_M_(cot_nshot)": {
    "f1_score": 0.0983606557377049,
    "accuracy": 45.0,
    "precision": 0.0857142857142857,
    "recall": 0.1153846153846153,
    "execution_time_mean": 2.4661160945892333,
    "execution_time_sd": 0.71186417624155,
    "eval_duration_mean": 2026680000.0,
    "prompt_eval_count_mean": 2048.0,
    "eval_count_mean": 236.91
  },
  "smallthinker:3b-preview-q4_K_M_(cot_nshot)": {
    "f1_score": 0.0,
    "accuracy": 0.0,
    "precision": 0.0,
    "recall": 0.0,
    "execution_time_mean": 5.326097011566162,
    "execution_time_sd": 0.0,
    "eval_duration_mean": 4838000000.0,
    "prompt_eval_count_mean": 2048.0,
    "eval_count_mean": 708.0
  }
}